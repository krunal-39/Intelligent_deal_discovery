{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48922269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment: genai_data (py3.10) | datasets==2.14.6 | pyarrow==12.0.1 | numpy<2\n",
    "\n",
    "import os, sys, multiprocessing, warnings, pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"CPU Cores Available:\", multiprocessing.cpu_count())\n",
    "\n",
    "# Create folders\n",
    "os.makedirs(\"../data/cleaned\", exist_ok=True)\n",
    "print(\"Folder ready â†’ data/cleaned (raw data cached by Hugging Face automatically)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a113cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"numpy<2.0.0\" \"datasets==2.14.6\" \"pyarrow==12.0.1\" pandas matplotlib seaborn tqdm\n",
    "\n",
    "from datasets import get_dataset_config_names, load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\", palette=\"crest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ID = \"McAuley-Lab/Amazon-Reviews-2023\"\n",
    "CLEAN_DIR = \"data/cleaned\"\n",
    "MIN_PRICE, MAX_PRICE = 0.5, 999.49\n",
    "MAX_WORKERS = 8   # \n",
    "\n",
    "print(f\"Dataset â†’ {DATASET_ID}\")\n",
    "print(f\"Using {MAX_WORKERS} CPU workers\")\n",
    "\n",
    "cols_to_keep = [\n",
    "    \"main_category\",\n",
    "    \"title\",\n",
    "    \"features\",\n",
    "    \"description\",\n",
    "    \"average_rating\",\n",
    "    \"rating_number\",\n",
    "    \"store\",\n",
    "    \"category\",\n",
    "    \"price_num\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02522ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_subset(subset_name: str):\n",
    "    \"\"\"Clean one subset and save as Parquet + CSV.\"\"\"\n",
    "    try:\n",
    "        ds = load_dataset(DATASET_ID, subset_name, split=\"full\")  \n",
    "        df = pd.DataFrame(ds)\n",
    "        df[\"category\"] = subset_name.replace(\"raw_meta_\", \"\")\n",
    "        df[\"price_num\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
    "\n",
    "        # Apply filters\n",
    "        df = df.dropna(subset=[\"price_num\"])\n",
    "        df = df[(df[\"price_num\"] >= MIN_PRICE) & (df[\"price_num\"] <= MAX_PRICE)]\n",
    "        df = df[df[\"title\"].astype(str).str.strip() != \"\"]\n",
    "        df = df[df[\"description\"].apply(lambda x: isinstance(x, list) and len(x) > 0)]\n",
    "\n",
    "        # Save to both formats\n",
    "        base = os.path.join(CLEAN_DIR, subset_name.replace(\"raw_meta_\", \"\"))\n",
    "        df.to_parquet(base + \"_clean.parquet\", index=False)\n",
    "        df.to_csv(base + \"_clean.csv\", index=False)\n",
    "\n",
    "        return subset_name, len(df)\n",
    "    except Exception as e:\n",
    "        return subset_name, f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fetching subset names for {DATASET_ID} â€¦\")\n",
    "subsets = get_dataset_config_names(DATASET_ID)\n",
    "meta_subsets = [s for s in subsets if s.startswith(\"raw_meta_\")]\n",
    "print(f\"Found {len(meta_subsets)} metadata subsets.\\n\")\n",
    "\n",
    "results = []\n",
    "with ProcessPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    futures = [ex.submit(clean_subset, s) for s in meta_subsets]\n",
    "    for f in tqdm(as_completed(futures), total=len(futures), desc=\"ðŸ§¹ Cleaning Subsets\"):\n",
    "        results.append(f.result())\n",
    "\n",
    "print(\"\\nCleaning Summary:\")\n",
    "for subset, res in results:\n",
    "    print(f\"  â€¢ {subset}: {res}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751eaac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Path to all cleaned parquet files\n",
    "parquet_files = sorted(glob(os.path.join(\"data/cleaned\", \"*_clean.parquet\")))\n",
    "\n",
    "columns_dict = {}\n",
    "\n",
    "print(f\"Inspecting {len(parquet_files)} cleaned subsets...\\n\")\n",
    "\n",
    "for file_path in parquet_files:\n",
    "    try:\n",
    "        table = pq.read_table(file_path)\n",
    "        columns = table.column_names\n",
    "        columns_dict[os.path.basename(file_path)] = columns\n",
    "        print(f\"{os.path.basename(file_path)} â†’ {len(columns)} columns\")\n",
    "    except Exception as e:\n",
    "        print(f\"{os.path.basename(file_path)} â†’ {e}\")\n",
    "\n",
    "print(\"\\n Summary:\")\n",
    "print(f\"Total files scanned: {len(columns_dict)}\")\n",
    "\n",
    "# Save the dictionary to a JSON for later inspection\n",
    "import json\n",
    "with open(\"data/cleaned/columns_summary.json\", \"w\") as f:\n",
    "    json.dump(columns_dict, f, indent=2)\n",
    "\n",
    "print(\"\\nColumns summary saved â†’ data/cleaned/columns_summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = sorted(glob(os.path.join(CLEAN_DIR, \"*_clean.parquet\")))\n",
    "print(f\"Merging {len(parquet_files)} cleaned subsets with selected columns ...\")\n",
    "\n",
    "tables = []\n",
    "for path in parquet_files:\n",
    "    try:\n",
    "        schema = pq.read_schema(path)\n",
    "        cols_in_file = [c for c in cols_to_keep if c in schema.names]\n",
    "        if not cols_in_file:\n",
    "            print(f\" Skipping {os.path.basename(path)} â†’ No matching columns\")\n",
    "            continue\n",
    "\n",
    "        # Read table\n",
    "        t = pq.read_table(path, columns=cols_in_file)\n",
    "\n",
    "        # Harmonize data types to avoid merge conflict\n",
    "        for name in t.schema.names:\n",
    "            if name in [\"price_num\", \"average_rating\", \"rating_number\"]:\n",
    "                # Always cast numeric fields to float64\n",
    "                t = t.set_column(t.schema.get_field_index(name),\n",
    "                                 name,\n",
    "                                 pa.compute.cast(t[name], pa.float64()))\n",
    "        tables.append(t)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {os.path.basename(path)} â†’ {e}\")\n",
    "\n",
    
    "# Step 2 â€“ Combine Tables Safely\n",
    "if tables:\n",
    "    combined = pa.concat_tables(tables, promote=True)\n",
    "    print(f\"Combined Arrow table: {combined.num_rows:,} rows, {len(combined.column_names)} columns\")\n",
    "else:\n",
    "    raise ValueError(\" tables were loaded successfully! Check your cleaned folder.\")\n",
    "\n",
    "# Step 3 â€“ Save Master Parquet\n",
    "final_parquet = os.path.join(CLEAN_DIR, \"amazon_reviews_2023_selected.parquet\")\n",
    "pq.write_table(combined, final_parquet, compression=\"snappy\")\n",
    "print(f\"Saved master Parquet â†’ {final_parquet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19830c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas for visualization (only lightweight columns)\n",
    "df_all = combined.select([c for c in cols_to_keep if c != \"description\" and c != \"features\"]).to_pandas()\n",
    "print(f\"Final DataFrame shape: {df_all.shape}\")\n",
    "\n",
    "# Optional: Save lightweight CSV (for human inspection)\n",
    "final_csv = os.path.join(CLEAN_DIR, \"amazon_reviews_2023_selected.csv\")\n",
    "df_all.to_csv(final_csv, index=False)\n",
    "print(f\"Saved CSV (light, no nested fields) â†’ {final_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Basic Statistics:\")\n",
    "\n",
    "# Only show stats for numeric columns if they exist\n",
    "numeric_cols = [col for col in [\"price_num\", \"average_rating\", \"rating_number\"] if col in df_all.columns]\n",
    "if numeric_cols:\n",
    "    display(df_all[numeric_cols].describe().T)\n",
    "else:\n",
    "    print(\" No numeric columns found for statistical summary.\")\n",
    "\n",
    "print(\"\\n Top 10 Categories by Count:\")\n",
    "\n",
    "if \"category\" in df_all.columns:\n",
    "    top_categories = df_all[\"category\"].value_counts().head(10)\n",
    "    display(top_categories)\n",
    "\n",
    "    # Optional barplot visualization for top categories\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=top_categories.values, y=top_categories.index, orient=\"h\", palette=\"crest\")\n",
    "    plt.title(\" Top 10 Product Categories by Count\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Number of Products\")\n",
    "    plt.ylabel(\"Category\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\" Column 'category' not found in dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35128e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "#  Unified High-Contrast Style\n",
    "\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\")\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (12, 6),\n",
    "    \"axes.edgecolor\": \"black\",\n",
    "    \"axes.linewidth\": 1.3,\n",
    "    \"grid.alpha\": 0.25,\n",
    "    \"axes.labelweight\": \"bold\",\n",
    "    \"axes.labelsize\": 13,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"font.weight\": \"medium\"\n",
    "})\n",
    "\n",
    "palette = sns.color_palette(\"coolwarm\", as_cmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d1e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1ï¸Price Distribution (Log Scale)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df_all[\"price_num\"], bins=80, kde=True, color=palette[0], edgecolor=\"black\", alpha=0.8)\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\" Price Distribution (Log Scale)\", fontsize=18, fontweight=\"bold\", pad=15)\n",
    "plt.xlabel(\"Product Price ($, log scale)\")\n",
    "plt.ylabel(\"Number of Products\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b41db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2 Average Rating Distribution\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df_all[\"average_rating\"].dropna(), bins=30, kde=True, color=palette[-1], edgecolor=\"black\", alpha=0.85)\n",
    "plt.title(\"Average Rating Distribution\", fontsize=18, fontweight=\"bold\", pad=15)\n",
    "plt.xlabel(\"Average Rating\")\n",
    "plt.ylabel(\"Number of Products\")\n",
    "plt.xlim(0.5, 5.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c4349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3ï¸Top Categories by Count (Cleaned & Spaced)\n",
    "if \"category\" in df_all.columns:\n",
    "    top_cats = df_all[\"category\"].value_counts().head(15)\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x=top_cats.values, y=top_cats.index, palette=\"viridis\", edgecolor=\"black\", alpha=0.9)\n",
    "    plt.title(\"Top 15 Product Categories by Count\", fontsize=18, fontweight=\"bold\", pad=15)\n",
    "    plt.xlabel(\"Number of Products\")\n",
    "    plt.ylabel(\"Category\")\n",
    "\n",
    "    # Limit x-axis labels to only first, middle, last for clarity\n",
    "    ax = plt.gca()\n",
    "    ticks = ax.get_xticks()\n",
    "    if len(ticks) > 3:\n",
    "        spaced_ticks = [ticks[0], ticks[len(ticks)//3], ticks[2*len(ticks)//3], ticks[-1]]\n",
    "        ax.set_xticks(spaced_ticks)\n",
    "        ax.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"{int(x):,}\"))\n",
    "    plt.grid(True, axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd91cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Average Price per Category\n",
    "if {\"price_num\", \"category\"} <= set(df_all.columns):\n",
    "    avg_price = (\n",
    "        df_all.groupby(\"category\")[\"price_num\"]\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(15)\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x=avg_price.values, y=avg_price.index, palette=\"mako\", edgecolor=\"black\", alpha=0.9)\n",
    "    plt.title(\"Average Price per Category (Top 15)\", fontsize=18, fontweight=\"bold\", pad=15)\n",
    "    plt.xlabel(\"Average Price ($)\")\n",
    "    plt.ylabel(\"Category\")\n",
    "    plt.grid(True, axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64462af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
